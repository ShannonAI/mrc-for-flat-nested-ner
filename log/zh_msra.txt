(mrc_venv) lixiaoya@junk-1:~/mrc-for-flat-nested-ner/script$ bash train_zh_msra.sh
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
Please notice that merge the args_dict and json_config ... ...
{
  "bert_frozen": "false",
  "hidden_size": 768,
  "hidden_dropout_prob": 0.2,
  "classifier_sign": "multi_nonlinear",
  "clip_grad": 1,
  "bert_config": {
    "attention_probs_dropout_prob": 0.1,
    "directionality": "bidi",
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.1,
    "hidden_size": 768,
    "initializer_range": 0.02,
    "intermediate_size": 3072,
    "max_position_embeddings": 512,
    "num_attention_heads": 12,
    "num_hidden_layers": 12,
    "pooler_fc_size": 768,
    "pooler_num_attention_heads": 12,
    "pooler_num_fc_layers": 3,
    "pooler_size_per_head": 128,
    "pooler_type": "first_token_transform",
    "type_vocab_size": 2,
    "vocab_size": 21128
  },
  "config_path": "/home/lixiaoya/mrc-for-flat-nested-ner/config/zh_bert.json",
  "data_dir": "/data/mrc_ner/zh_msra",
  "bert_model": "/data/pretrain_ckpt/chinese_L-12_H-768_A-12",
  "task_name": null,
  "max_seq_length": 256,
  "train_batch_size": 8,
  "dev_batch_size": 16,
  "test_batch_size": 16,
  "checkpoint": 2400,
  "learning_rate": 1e-05,
  "num_train_epochs": 12,
  "warmup_proportion": -1.0,
  "local_rank": -1,
  "gradient_accumulation_steps": 1,
  "seed": 2333,
  "output_dir": "/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3",
  "data_sign": "zh_msra",
  "weight_start": 1.0,
  "weight_end": 1.0,
  "weight_span": 1.0,
  "entity_sign": "flat",
  "n_gpu": 1,
  "dropout": 0.3,
  "entity_threshold": 0.5,
  "data_cache": true,
  "export_model": true,
  "do_lower_case": false
}
-*--*--*--*--*--*--*--*--*--*-
current data_sign: zh_msra
=*==*==*==*==*==*==*==*==*==*=
loading train data ... ...
125184
125184 train data loaded
=*==*==*==*==*==*==*==*==*==*=
loading dev data ... ...
13908
13908 dev data loaded
=*==*==*==*==*==*==*==*==*==*=
loading test data ... ...
13095
13095 test data loaded
######################################################################
EPOCH:  0
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.495831358828582e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0021 0.928 0.8248 0.8426 0.8336
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_0_2400.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0026 0.8657 0.8231 0.8458 0.8343
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0007669293554499745
............................................................
DEV: loss, acc, precision, recall, f1
0.0014 0.9448 0.8802 0.8986 0.8893
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_0_4800.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0016 0.9416 0.9146 0.9162 0.9154
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.009198719635605812
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.9527 0.8982 0.9217 0.9098
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_0_7200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0013 0.9445 0.9163 0.9366 0.9263
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00040529490797780454
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.9579 0.9077 0.9301 0.9187
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_0_9600.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0012 0.9601 0.936 0.9503 0.9431
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00044453490409068763
............................................................
DEV: loss, acc, precision, recall, f1
0.0017 0.9305 0.8006 0.9532 0.8702
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.002554914215579629
............................................................
DEV: loss, acc, precision, recall, f1
0.0012 0.9529 0.9151 0.9179 0.9165
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  1
current learning rate 9.5e-06
current learning rate 9.5e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.6252072277420666e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.9616 0.9294 0.924 0.9267
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_1_2400.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0011 0.9583 0.9383 0.9408 0.9396
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.000218949222471565
............................................................
DEV: loss, acc, precision, recall, f1
0.001 0.9604 0.9029 0.943 0.9225
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.001913223648443818
............................................................
DEV: loss, acc, precision, recall, f1
0.001 0.9671 0.9326 0.9392 0.9359
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_1_7200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0011 0.9629 0.9489 0.9465 0.9477
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00023418816272169352
............................................................
DEV: loss, acc, precision, recall, f1
0.001 0.9632 0.9131 0.9453 0.9289
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
5.476089063449763e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.001 0.9614 0.9117 0.9476 0.9293
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0017070714384317398
............................................................
DEV: loss, acc, precision, recall, f1
0.001 0.9613 0.9048 0.9443 0.9241
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  2
current learning rate 9.025e-06
current learning rate 9.025e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.3494891391019337e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.9658 0.9272 0.9321 0.9296
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
5.7943110732594505e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.001 0.9686 0.9233 0.9461 0.9346
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0005047316080890596
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.9685 0.9291 0.9464 0.9376
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_2_7200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0012 0.9736 0.9511 0.9581 0.9546
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00020908881560899317
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.966 0.9161 0.9553 0.9353
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.4358687369385734e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.9643 0.9302 0.9291 0.9297
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0020213215611875057
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.9622 0.9022 0.9522 0.9265
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  3
current learning rate 8.57375e-06
current learning rate 8.57375e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
8.072249784163432e-07
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.9695 0.9361 0.938 0.937
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
5.57252460566815e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.9676 0.922 0.9491 0.9354
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00026581098791211843
............................................................
DEV: loss, acc, precision, recall, f1
0.0012 0.9703 0.942 0.9367 0.9393
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_3_7200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0013 0.9728 0.9636 0.9538 0.9587
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0004669780028052628
............................................................
DEV: loss, acc, precision, recall, f1
0.0012 0.9665 0.9155 0.9558 0.9352
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.2759457351639867e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0011 0.9652 0.9203 0.9489 0.9344
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0003391021164134145
............................................................
DEV: loss, acc, precision, recall, f1
0.0012 0.969 0.9242 0.9489 0.9364
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  4
current learning rate 8.1450625e-06
current learning rate 8.1450625e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
5.089864316687454e-07
............................................................
DEV: loss, acc, precision, recall, f1
0.0012 0.9698 0.9329 0.9405 0.9367
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
4.389393870951608e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0012 0.9685 0.9209 0.953 0.9366
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0005505782319232821
............................................................
DEV: loss, acc, precision, recall, f1
0.0012 0.9722 0.9478 0.9329 0.9403
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_4_7200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0013 0.9739 0.9615 0.95 0.9557
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.4746415622066706e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0014 0.9663 0.9136 0.9542 0.9335
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.887955477286596e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0013 0.9693 0.9384 0.9405 0.9394
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.5870403987937607e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0013 0.9694 0.9239 0.9476 0.9356
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  5
current learning rate 7.737809375e-06
current learning rate 7.737809375e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.3120082914829254e-07
............................................................
DEV: loss, acc, precision, recall, f1
0.0013 0.9711 0.9409 0.9436 0.9422
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_5_2400.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0015 0.9721 0.9551 0.9536 0.9544
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
4.4484444515546784e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0013 0.9693 0.9273 0.9596 0.9431
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_5_4800.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0016 0.9729 0.9456 0.9604 0.9529
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
5.4526339226868004e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0013 0.971 0.9395 0.9479 0.9437
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_5_7200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0015 0.9745 0.9553 0.9579 0.9566
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.091046528425068e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0014 0.9701 0.9318 0.9547 0.9431
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.9003464331035502e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0014 0.9675 0.932 0.9474 0.9396
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00033739052014425397
............................................................
DEV: loss, acc, precision, recall, f1
0.0014 0.9682 0.9339 0.938 0.9359
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  6
current learning rate 7.35091890625e-06
current learning rate 7.35091890625e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.6775524020195007e-07
............................................................
DEV: loss, acc, precision, recall, f1
0.0014 0.9693 0.9173 0.9565 0.9365
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
4.2467290768399835e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9707 0.9366 0.9461 0.9413
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
9.407805919181556e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0014 0.9688 0.9279 0.9522 0.9399
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.316003130748868e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0014 0.9686 0.9296 0.954 0.9416
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.7894555639941245e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9688 0.9264 0.9512 0.9387
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.0088810995512176e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9711 0.9349 0.9491 0.942
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  7
current learning rate 6.9833729609374995e-06
current learning rate 6.9833729609374995e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
5.588049134530593e-08
............................................................
DEV: loss, acc, precision, recall, f1
0.0016 0.9707 0.9362 0.9507 0.9434
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
4.144330523558892e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9687 0.9239 0.9542 0.9388
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
7.991971506271511e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9714 0.9343 0.9542 0.9442
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_7_7200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0017 0.9759 0.9541 0.9604 0.9573
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00010544765973463655
............................................................
DEV: loss, acc, precision, recall, f1
0.0016 0.9695 0.931 0.9578 0.9442
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.648778015805874e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0016 0.9704 0.9298 0.9563 0.9428
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.7766615201253444e-07
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9692 0.9361 0.938 0.937
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  8
current learning rate 6.634204312890624e-06
current learning rate 6.634204312890624e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
4.47041657025693e-08
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9705 0.935 0.9507 0.9428
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.835403185803443e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0016 0.9695 0.9293 0.9525 0.9407
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
5.704716022592038e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9708 0.9328 0.9527 0.9426
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.8649343221331947e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9715 0.9351 0.9519 0.9434
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.6234653230640106e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0016 0.9712 0.9343 0.954 0.944
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
8.382039595744573e-08
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9713 0.9379 0.9446 0.9412
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  9
current learning rate 6.302494097246093e-06
current learning rate 6.302494097246093e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.4226104617118835e-08
............................................................
DEV: loss, acc, precision, recall, f1
0.0017 0.9727 0.9429 0.9402 0.9416
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.970294710597955e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0017 0.9718 0.9347 0.9537 0.9441
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
4.7263092710636556e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0016 0.9717 0.9358 0.9519 0.9438
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.311477692273911e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0016 0.9711 0.9395 0.9474 0.9434
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.4394844583875965e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.971 0.9359 0.9502 0.943
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.8883172237547114e-08
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9702 0.9341 0.9514 0.9427
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  10
current learning rate 5.9873693923837885e-06
current learning rate 5.9873693923837885e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.770707396848593e-08
............................................................
DEV: loss, acc, precision, recall, f1
0.0015 0.9709 0.9337 0.9497 0.9416
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.93561931559816e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0017 0.9721 0.9458 0.9456 0.9457
SAVED model path is :
/data/output_mrc_ner/zh_msra_256_1e-5_8_0.3/bert_finetune_model_10_4800.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0018 0.9748 0.9614 0.956 0.9587
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
4.647794776246883e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0016 0.9717 0.9367 0.9527 0.9447
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.2481277483166195e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0017 0.9712 0.938 0.9509 0.9444
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.4600318536395207e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0017 0.971 0.9388 0.9479 0.9433
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.282934812887106e-08
............................................................
DEV: loss, acc, precision, recall, f1
0.0017 0.9711 0.9387 0.9507 0.9447
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=
Best DEV : overall best loss, acc, precision, recall, f1
0.0017 0.9721 0.9458 0.9456 0.9457
scores on TEST when Best DEV:loss, acc, precision, recall, f1
0.0018 0.9748 0.9614 0.956 0.9587
=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=