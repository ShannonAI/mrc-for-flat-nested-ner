lixiaoya@junk-3:/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1$ cat log.txt
Please notice that merge the args_dict and json_config ... ...
{
  "bert_frozen": "false",
  "hidden_size": 1024,
  "hidden_dropout_prob": 0.2,
  "classifier_sign": "multi_nonlinear",
  "clip_grad": 1,
  "bert_config": {
    "attention_probs_dropout_prob": 0.1,
    "directionality": "bidi",
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.1,
    "hidden_size": 1024,
    "initializer_range": 0.02,
    "intermediate_size": 4096,
    "max_position_embeddings": 512,
    "num_attention_heads": 16,
    "num_hidden_layers": 24,
    "pooler_fc_size": 768,
    "pooler_num_attention_heads": 12,
    "pooler_num_fc_layers": 3,
    "pooler_size_per_head": 128,
    "pooler_type": "first_token_transform",
    "type_vocab_size": 2,
    "vocab_size": 28996
  },
  "config_path": "/home/lixiaoya/mrc-for-flat-nested-ner/config/en_bert_large_cased.json",
  "data_dir": "/mnt/mrc_ner_data/conll2003",
  "bert_model": "/mnt/pretrain_ckpt/cased_L-24_H-1024_A-16",
  "task_name": null,
  "max_seq_length": 160,
  "train_batch_size": 4,
  "dev_batch_size": 12,
  "test_batch_size": 16,
  "checkpoint": 800,
  "learning_rate": 2e-05,
  "num_train_epochs": 6,
  "warmup_proportion": -1.0,
  "max_grad_norm": 1.0,
  "gradient_accumulation_steps": 1,
  "seed": 2333,
  "output_dir": "/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1",
  "data_sign": "conll03",
  "weight_start": 0.5,
  "weight_end": 0.5,
  "weight_span": 1.0,
  "entity_sign": "flat",
  "n_gpu": 1,
  "dropout": 0.1,
  "entity_threshold": 0.5,
  "num_data_processor": 10,
  "data_cache": true,
  "export_model": true,
  "do_lower_case": false,
  "fp16": false,
  "amp_level": "O2",
  "local_rank": -1
}
-*--*--*--*--*--*--*--*--*--*-
current data_sign: conll03
=*==*==*==*==*==*==*==*==*==*=
loading train data ... ...
56160
%%%% %%%% Load Saved Cache files in /mnt/mrc_ner_data/conll2003 %%% %%%
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.train.cache.160.10-2 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.train.cache.160.10-0 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.train.cache.160.10-3 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.train.cache.160.10-7 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.train.cache.160.10-9 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.train.cache.160.10-8 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.train.cache.160.10-6 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.train.cache.160.10-1 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.train.cache.160.10-4 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.train.cache.160.10-5 <<< <<< <<<
check number of examples before and after data processing :
56160 56160
56160 train data loaded
=*==*==*==*==*==*==*==*==*==*=
loading dev data ... ...
12996
%%%% %%%% Load Saved Cache files in /mnt/mrc_ner_data/conll2003 %%% %%%
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.dev.cache.160.10-6 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.dev.cache.160.10-4 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.dev.cache.160.10-8 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.dev.cache.160.10-3 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.dev.cache.160.10-9 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.dev.cache.160.10-1 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.dev.cache.160.10-2 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.dev.cache.160.10-7 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.dev.cache.160.10-5 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.dev.cache.160.10-0 <<< <<< <<<
check number of examples before and after data processing :
12996 12996
12996 dev data loaded
=*==*==*==*==*==*==*==*==*==*=
loading test data ... ...
13808
%%%% %%%% Load Saved Cache files in /mnt/mrc_ner_data/conll2003 %%% %%%
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.test.cache.160.10-8 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.test.cache.160.10-7 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.test.cache.160.10-9 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.test.cache.160.10-1 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.test.cache.160.10-6 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.test.cache.160.10-3 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.test.cache.160.10-4 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.test.cache.160.10-5 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.test.cache.160.10-0 <<< <<< <<<
load sliced features from : /mnt/mrc_ner_data/conll2003/mrc-ner.test.cache.160.10-2 <<< <<< <<<
check number of examples before and after data processing :
13808 13808
13808 test data loaded
######################################################################
EPOCH:  0
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.013114433735609055
............................................................
DEV: loss, acc, precision, recall, f1
0.0442 0.1588 0.0733 0.6815 0.1323
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_0_800.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0452 0.1673 0.0667 0.6875 0.1216
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.025870945304632187
............................................................
DEV: loss, acc, precision, recall, f1
0.0556 0.6165 0.2901 0.4888 0.3641
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_0_1600.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0705 0.6357 0.2664 0.4552 0.3361
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00019412676920183003
............................................................
DEV: loss, acc, precision, recall, f1
0.0268 0.3415 0.1946 0.8376 0.3159
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0001407224772265181
............................................................
DEV: loss, acc, precision, recall, f1
0.0186 0.5061 0.2937 0.826 0.4333
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_0_3200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0276 0.5168 0.2481 0.7793 0.3764
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.018912024796009064
............................................................
DEV: loss, acc, precision, recall, f1
0.0281 0.6741 0.2427 0.6825 0.3581
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00037116973544470966
............................................................
DEV: loss, acc, precision, recall, f1
0.0374 0.6714 0.5479 0.8372 0.6624
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_0_4800.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0569 0.6471 0.4962 0.7946 0.6109
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0009345253347419202
............................................................
DEV: loss, acc, precision, recall, f1
0.0149 0.7684 0.3999 0.8827 0.5504
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00014036099310033023
............................................................
DEV: loss, acc, precision, recall, f1
0.0162 0.8036 0.5079 0.8593 0.6384
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.18426990509033203
............................................................
DEV: loss, acc, precision, recall, f1
0.0142 0.7402 0.3743 0.8564 0.521
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0027512144297361374
............................................................
DEV: loss, acc, precision, recall, f1
0.0111 0.6482 0.4206 0.8943 0.5722
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.011884676292538643
............................................................
DEV: loss, acc, precision, recall, f1
0.0133 0.3748 0.2375 0.9212 0.3777
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.020558737218379974
............................................................
DEV: loss, acc, precision, recall, f1
0.0277 0.4824 0.3084 0.7489 0.4369
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.002887663198634982
............................................................
DEV: loss, acc, precision, recall, f1
0.0122 0.5898 0.4082 0.8929 0.5602
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00046240026131272316
............................................................
DEV: loss, acc, precision, recall, f1
0.0127 0.8037 0.4712 0.8908 0.6163
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.016193868592381477
............................................................
DEV: loss, acc, precision, recall, f1
0.0145 0.6095 0.4755 0.8297 0.6046
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.011213354766368866
............................................................
DEV: loss, acc, precision, recall, f1
0.0108 0.4034 0.3589 0.8977 0.5127
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
4.337587233749218e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0142 0.8026 0.6432 0.878 0.7424
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_0_13600.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0238 0.805 0.6054 0.8529 0.7082
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  1
current learning rate 1.9e-05
current learning rate 1.9e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
7.149128941819072e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.015 0.0 0.101 0.8951 0.1816
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0008350273128598928
............................................................
DEV: loss, acc, precision, recall, f1
0.0412 0.3921 0.2631 0.8564 0.4025
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00011953206558246166
............................................................
DEV: loss, acc, precision, recall, f1
0.0125 0.0 0.161 0.8835 0.2723
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
8.817347406875342e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0103 0.2114 0.165 0.9261 0.2801
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00013102043885737658
............................................................
DEV: loss, acc, precision, recall, f1
0.0125 0.4484 0.2404 0.914 0.3807
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0003489914524834603
............................................................
DEV: loss, acc, precision, recall, f1
0.0139 0.4356 0.42 0.8975 0.5722
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0001643352152314037
............................................................
DEV: loss, acc, precision, recall, f1
0.0122 0.8536 0.6264 0.9123 0.7428
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_1_5600.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0287 0.8295 0.5749 0.8703 0.6924
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
6.166055391076952e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0125 0.8299 0.5751 0.9187 0.7074
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0009145520161837339
............................................................
DEV: loss, acc, precision, recall, f1
0.0111 0.8681 0.6944 0.8998 0.7839
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_1_7200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0269 0.841 0.6307 0.8577 0.7269
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00025839850422926247
............................................................
DEV: loss, acc, precision, recall, f1
0.0111 0.4298 0.3673 0.9066 0.5228
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0004722985322587192
............................................................
DEV: loss, acc, precision, recall, f1
0.0131 0.2341 0.1202 0.9259 0.2128
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0004719519638456404
............................................................
DEV: loss, acc, precision, recall, f1
0.0215 0.3852 0.3161 0.8573 0.4619
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0005801439983770251
............................................................
DEV: loss, acc, precision, recall, f1
0.0134 0.8901 0.7294 0.912 0.8105
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_1_10400.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.029 0.8661 0.6853 0.8648 0.7646
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
7.97920220065862e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0124 0.3878 0.2945 0.9234 0.4466
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0047669303603470325
............................................................
DEV: loss, acc, precision, recall, f1
0.01 0.6796 0.4738 0.9083 0.6227
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0033753542229533195
............................................................
DEV: loss, acc, precision, recall, f1
0.0115 0.2351 0.2518 0.9108 0.3945
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.477545760688372e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0122 0.3325 0.2692 0.9014 0.4146
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  2
current learning rate 1.805e-05
current learning rate 1.805e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
8.494493522448465e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0139 0.2403 0.3303 0.9113 0.4849
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00010088890849146992
............................................................
DEV: loss, acc, precision, recall, f1
0.0212 0.6944 0.5311 0.9148 0.672
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.242001912440173e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0141 0.033 0.1476 0.9312 0.2549
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
4.2210405808873475e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0148 0.2064 0.1852 0.9062 0.3076
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00010834523709490895
............................................................
DEV: loss, acc, precision, recall, f1
0.0152 0.3469 0.2147 0.932 0.3491
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00014005838602315634
............................................................
DEV: loss, acc, precision, recall, f1
0.0136 0.8268 0.5067 0.9195 0.6534
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0001709922798909247
............................................................
DEV: loss, acc, precision, recall, f1
0.0177 0.1197 0.3803 0.9012 0.5349
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
6.407947512343526e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0162 0.551 0.3418 0.9126 0.4974
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.011364147067070007
............................................................
DEV: loss, acc, precision, recall, f1
0.0169 0.4811 0.3144 0.9069 0.4669
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0001545063714729622
............................................................
DEV: loss, acc, precision, recall, f1
0.0142 0.7927 0.5096 0.9098 0.6533
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0005284530343487859
............................................................
DEV: loss, acc, precision, recall, f1
0.0141 0.8221 0.5535 0.9281 0.6935
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0001204392610816285
............................................................
DEV: loss, acc, precision, recall, f1
0.0161 0.637 0.3605 0.9175 0.5176
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0006699705263599753
............................................................
DEV: loss, acc, precision, recall, f1
0.0138 0.8859 0.7001 0.9029 0.7886
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00026676536072045565
............................................................
DEV: loss, acc, precision, recall, f1
0.0107 0.8162 0.5391 0.919 0.6796
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.006293425802141428
............................................................
DEV: loss, acc, precision, recall, f1
0.0116 0.8597 0.6546 0.8968 0.7568
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00030608600354753435
............................................................
DEV: loss, acc, precision, recall, f1
0.0134 0.894 0.7221 0.9216 0.8097
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.3127109014021698e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0131 0.8681 0.7047 0.911 0.7947
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  3
current learning rate 1.71475e-05
current learning rate 1.71475e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
5.3158903028815985e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0182 0.6662 0.2676 0.9121 0.4138
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
7.778636063449085e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0222 0.6801 0.6707 0.9101 0.7723
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.9535423891502433e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0169 0.7863 0.6161 0.9241 0.7393
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.3150023733032867e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0159 0.6726 0.2995 0.9305 0.4532
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
4.7338624426629394e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0157 0.6462 0.2393 0.9209 0.3799
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00012382595741655678
............................................................
DEV: loss, acc, precision, recall, f1
0.013 0.7633 0.6078 0.9305 0.7353
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.8570997528731823e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0129 0.8828 0.6977 0.9221 0.7944
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.0417351808864623e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.015 0.8353 0.5133 0.9382 0.6636
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0002658739686012268
............................................................
DEV: loss, acc, precision, recall, f1
0.0114 0.8563 0.5762 0.9323 0.7122
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
9.782484266906977e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0164 0.8175 0.4119 0.9268 0.5704
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0005488301976583898
............................................................
DEV: loss, acc, precision, recall, f1
0.016 0.8511 0.5994 0.9354 0.7306
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
7.114094478311017e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0129 0.6094 0.5416 0.9281 0.684
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0004951147711835802
............................................................
DEV: loss, acc, precision, recall, f1
0.0172 0.3886 0.5577 0.9239 0.6955
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
5.577351475949399e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0135 0.8565 0.576 0.9352 0.7129
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0018427843460813165
............................................................
DEV: loss, acc, precision, recall, f1
0.0109 0.8779 0.7099 0.9333 0.8064
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.4637032765895128e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0148 0.888 0.7356 0.9244 0.8193
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_3_12800.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0334 0.8605 0.6797 0.8853 0.769
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.2007218174403533e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0111 0.8963 0.7963 0.9147 0.8514
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_3_13600.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0246 0.8709 0.7462 0.8713 0.8039
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  4
current learning rate 1.6290125e-05
current learning rate 1.6290125e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.06360780086834e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.014 0.6542 0.4185 0.9364 0.5784
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00017323433712590486
............................................................
DEV: loss, acc, precision, recall, f1
0.0162 0.686 0.5859 0.9315 0.7193
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.0882835087832063e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0169 0.8853 0.741 0.9327 0.8258
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
6.464307716669282e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0158 0.8244 0.7016 0.9354 0.8018
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.2973663615412079e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.018 0.9109 0.8799 0.9113 0.8953
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_4_4000.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0378 0.8889 0.8414 0.8727 0.8568
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
6.469764048233628e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0139 0.9172 0.8878 0.9187 0.903
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_4_4800.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0328 0.8831 0.8423 0.8662 0.8541
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.2363027053652331e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0157 0.9152 0.8659 0.9291 0.8964
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.8630503948079422e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0175 0.1462 0.8454 0.9269 0.8843
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0003887152415700257
............................................................/home/lixiaoya/mrc-for-flat-nested-ner/layer/optim.py:111: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)

DEV: loss, acc, precision, recall, f1
0.0168 0.8442 0.6194 0.9145 0.7385
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.876519258483313e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0151 0.8747 0.7144 0.92 0.8043
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
5.608050923910923e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0176 0.8646 0.6591 0.9285 0.7709
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.3446093362290412e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0188 0.8613 0.6866 0.934 0.7914
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00020169379422441125
............................................................
DEV: loss, acc, precision, recall, f1
0.0166 0.8784 0.7326 0.9293 0.8193
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.3298094674828462e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.015 0.8897 0.7449 0.9227 0.8244
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00042990216752514243
............................................................
DEV: loss, acc, precision, recall, f1
0.0113 0.8997 0.7593 0.9305 0.8362
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.079803016385995e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0157 0.8964 0.7911 0.9382 0.8584
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.957324639079161e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0172 0.9182 0.8737 0.9372 0.9043
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_4_13600.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0371 0.8925 0.8316 0.897 0.8631
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  5
current learning rate 1.547561875e-05
current learning rate 1.547561875e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.6384890588815324e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0176 0.9027 0.8414 0.9409 0.8884
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
9.878078344627284e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0183 0.9046 0.7953 0.9451 0.8638
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.404032784397714e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0154 0.9211 0.9065 0.9251 0.9157
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_5_2400.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0341 0.9019 0.8655 0.8875 0.8763
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
7.1739195846021175e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0177 0.9227 0.8753 0.9384 0.9058
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.021957905322779e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0169 0.9186 0.873 0.9416 0.906
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00022597656061407179
............................................................
DEV: loss, acc, precision, recall, f1
0.0135 0.9494 0.9356 0.9364 0.936
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_5_4800.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0333 0.9209 0.8926 0.8986 0.8956
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.4289753380580805e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0147 0.9313 0.8997 0.9281 0.9137
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
7.428909157169983e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0174 0.9168 0.8532 0.9275 0.8888
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.0006078280210495
............................................................
DEV: loss, acc, precision, recall, f1
0.0183 0.9619 0.9573 0.9791 0.9681
SAVED model path is :
/mnt/output_mrc_ner/conll03_160_2e-5_4_0.1/bert_finetune_model_5_7200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0333 0.9612 0.9369 0.9241 0.9304
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.9739509298233315e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0182 0.8822 0.7655 0.9194 0.8354
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.005541680380702019
............................................................
DEV: loss, acc, precision, recall, f1
0.0174 0.9086 0.8437 0.9264 0.8831
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
2.4090095394058153e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0163 0.8935 0.8115 0.9374 0.8699
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00037032965337857604
............................................................
DEV: loss, acc, precision, recall, f1
0.02 0.8765 0.7118 0.9275 0.8054
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
1.0040821507573128e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0178 0.8831 0.6902 0.9323 0.7932
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
0.00039541840669699013
............................................................
DEV: loss, acc, precision, recall, f1
0.0135 0.9419 0.9062 0.9313 0.9186
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
9.65240178629756e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0167 0.9495 0.9069 0.9251 0.9159
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is :
3.948317498725373e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0149 0.9481 0.914 0.9379 0.9258
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=
Best DEV : overall best loss, acc, precision, recall, f1
0.0183 0.9619 0.9573 0.9791 0.9681
scores on TEST when Best DEV:loss, acc, precision, recall, f1
0.0333 0.9612 0.9369 0.9241 0.9304
=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=